{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build matrices notebooks\n",
    "This notebook is used to develop the matrices that will be used for analysis. Based on learnings from the exploratory notebook \"Starbucks_Capstone_notebook.ipynb\". I have defined a set of parameteres that has to be derived from the combination of portfolio, profile and transcript data. \n",
    "\n",
    "## Interaction matrices\n",
    "In princple I have decided to make two main matrices. One focusing on the users, and one focusing on the offers given. \n",
    "\n",
    "Documentation of the columns for each matrix is given in a separate description. XXINSERT_REF\n",
    "\n",
    "### Offer based interactions\n",
    "The offers dataframe will have one line per offer given to a user. Each line will consist of data related to the offer, taken from the portfolio data, data related to user identity, taken from the profile data, and data related to user interactions with the given offer, derived from the transcript data. This matrix will be the basis for investigating the user - offer interactions. \n",
    "\n",
    "### User based interactions\n",
    "The profile_exp dataframe will be built with one row per user (in principle an expansion of the profile.json data. The expansion will provide features about the user, user details as provided in the original profile data, and aggregated features about the users offer and spending history. This matrix will be used for segmentation analysis of the users and their interactions. \n",
    "\n",
    "## Info\n",
    "The functions created in this notebook will be moved to different python modules as seen fit. There are a lot of helper methods needed to build both matrices, and these can be investigated in detail below, or in the \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from collections import OrderedDict\n",
    "%matplotlib inline\n",
    "\n",
    "from utils.cleaning import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the json files\n",
    "portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('data/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('data/transcript.json', orient='records', lines=True)\n",
    "\n",
    "#for simplicity I will not keep the original dataframes\n",
    "portfolio, profile, transcript = clean_data(portfolio, profile, transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offer based interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to separate each offer the user receives. Each offer will be treated as a unique offering, identified by the offer_id, the user_id. Based on the instructions on the data I am making a few assumptions and create some definitions to limit the solution space. \n",
    "\n",
    "First, I define a \"valid windom\" as the window from the offer is viewed to its complettion. Completion in this case will be defined as the first event of offer completed or offer expires. Parameters related to what happens inside this valid window is denoted with \"...\\_in\\_window\". \n",
    "\n",
    "The rest of the total window will then be defined as not valid, or \"...\\_out\\_window\". \n",
    "\n",
    "Anything happening outside of the window defined by the \"offer received\"-time and after the duration is passed will not be considered in this matrix. The user based interaction matrix will create parameters that transcends the specific offering such as spendings outside valid windows and offerings. \n",
    "\n",
    "One user can receive a specific offer_id several times. If these are overlapping, we will be in trouble with difficulty to differentiate the offers. At the moment we will close our eyes and hope that this is not happening to any users. It would seem counter productive to offer two bogo offers of the same kind at the same time to the same users. Also, the user doesn't need to have information twice about the same offering, one should hope at least. \n",
    "\n",
    "We are also not differentiating if the user has two or more offers at the same time. The aggregated data from transactions during the offer is performed per offer user receives. Thus, transactions that occurs inside window of more than one offer at the same time will be double booked. This is in principle no problem when focusing on offers by itself, as we cannot really differentiate which offer (at least not immediately) that influence the user the most. Hence, we make an assumption that each offer is independent from another regardless of time of occurence. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 received no offer\n"
     ]
    }
   ],
   "source": [
    "def get_user_offer_ids(user_transcript):\n",
    "    \"\"\"\n",
    "    Extracts offer ids presented to the user    \n",
    "    \"\"\"\n",
    "    offer_ids = [(i, offer_id) for i, offer_id in\n",
    "                 enumerate(user_transcript.loc[user_transcript['event'] == 'offer received', 'offer_id'])]\n",
    "    return offer_ids\n",
    "\n",
    "def get_user_offer_starts(user_transcript):\n",
    "    \"\"\"\n",
    "    Extracts start times of offers presented to the user    \n",
    "    \"\"\"\n",
    "    offers_start = np.array(user_transcript.loc[user_transcript['event'] == 'offer received', 'time'])\n",
    "    return offers_start\n",
    "\n",
    "def get_user_offer_types(portfolio, offer_ids):\n",
    "    \"\"\"\n",
    "    Extracts offer types of offers presented to the user    \n",
    "    \"\"\"\n",
    "    offers_type = np.array(\n",
    "        [portfolio.loc[portfolio['id'] == offer_id, 'offer_type'].values.astype(str)[0] for offer_id in offer_ids])\n",
    "    return offers_type\n",
    "def get_user_offer_difficulties(portfolio, offer_ids):\n",
    "    \"\"\"\n",
    "    Extracts difficulty of offers presented to the user    \n",
    "    \"\"\"\n",
    "    offers_difficulty = np.array(\n",
    "        [portfolio.loc[portfolio['id'] == offer_id, 'difficulty'].values.astype(str)[0] for offer_id in offer_ids])\n",
    "    return offers_difficulty\n",
    "\n",
    "def get_user_offer_rewards(portfolio, offer_ids):\n",
    "    \"\"\"\n",
    "    Extracts difficulty of offers presented to the user    \n",
    "    \"\"\"\n",
    "    offers_reward = np.array(\n",
    "        [portfolio.loc[portfolio['id'] == offer_id, 'reward'].values.astype(str)[0] for offer_id in offer_ids])\n",
    "    return offers_reward\n",
    "    \n",
    "def get_user_offer_durations(portfolio, offer_ids):\n",
    "    \"\"\"\n",
    "    Extracts difficulty of offers presented to the user    \n",
    "    \"\"\"\n",
    "    offers_duration = np.array(\n",
    "        [portfolio.loc[portfolio['id'] == offer_id, 'duration'].values.astype(int)[0] * 24 for offer_id in offer_ids])\n",
    "    return offers_duration\n",
    "    \n",
    "def get_user_offer_views(user_transcript):\n",
    "    \"\"\"\n",
    "    Extracts difficulty of offers presented to the user    \n",
    "    \"\"\"\n",
    "    offers_viewed = np.array(user_transcript.loc[user_transcript['event'] == 'offer viewed', ['time', 'offer_id']])\n",
    "    return offers_viewed\n",
    "\n",
    "def get_user_offer_completions(user_transcript):\n",
    "    \"\"\"\n",
    "    Extracts difficulty of offers presented to the user    \n",
    "    \"\"\"\n",
    "    offers_completed = np.array(\n",
    "        user_transcript.loc[user_transcript['event'] == 'offer completed', ['time', 'offer_id']])\n",
    "    return offers_completed\n",
    "\n",
    "    \n",
    "def build_offer_df(portfolio, profile, transcript):\n",
    "    #iterate over users\n",
    "    users = profile['id'].unique()\n",
    "    \n",
    "    offers = {}\n",
    "    count = 0\n",
    "    count_users_no_offer = 0\n",
    "    for user in users:\n",
    "        # transcripts for specific user\n",
    "        user_transcript = transcript.loc[transcript['id'] == user, :]\n",
    "        user_transactions = user_transcript.loc[user_transcript['event'] == 'transaction', ['time', 'amount']]        \n",
    "        offer_ids_tuples = get_user_offer_ids(user_transcript)\n",
    "        if len(offer_ids_tuples)<1: #if there are no offers given to user, skip the rest. \n",
    "            count_users_no_offer += 1\n",
    "            continue\n",
    "        offer_ids = list(list(zip(*offer_ids_tuples))[1])\n",
    "        \n",
    "        offers_start = get_user_offer_starts(user_transcript)\n",
    "        offers_duration = get_user_offer_durations(portfolio, offer_ids)\n",
    "        offers_difficulty = get_user_offer_difficulties(portfolio, offer_ids)\n",
    "        offers_reward = get_user_offer_rewards(portfolio, offer_ids) \n",
    "        offers_type = get_user_offer_types(portfolio, offer_ids)\n",
    "        offers_viewed = get_user_offer_views(user_transcript) \n",
    "        offers_completed = get_user_offer_completions(user_transcript)\n",
    "        \n",
    "        offers_end = offers_start + offers_duration\n",
    "        \n",
    "        #Test if results are as expected\n",
    "        assert len(offer_ids) == len(offers_start) , \"The number of offerings ({}) are not the same as the number of starting points ({})\".format(len(offer_ids), len(offers_start))\n",
    "        assert len(offer_ids) == len(offers_type) , \"The number of offerings ({}) are not the same as the number of offer types ({})\".format(len(offer_ids), len(offers_type))\n",
    "        assert len(offer_ids) == len(offers_difficulty) , \"The number of offerings ({}) are not the same as the number of offer difficulties ({})\".format(len(offer_ids), len(offers_difficulty))\n",
    "        assert len(offer_ids) == len(offers_reward) , \"The number of offerings ({}) are not the same as the number of offer rewards ({})\".format(len(offer_ids), len(offers_reward))\n",
    "        assert len(offer_ids) == len(offers_duration) , \"The number of offerings ({}) are not the same as the number of offer durations ({})\".format(len(offer_ids), len(offers_duration))\n",
    "        \n",
    "        #iterate over offers and build dict to be used to fill a dataframe\n",
    "        for i, offer_id in offer_ids_tuples:\n",
    "            start = offers_start[i]\n",
    "            duration = offers_duration[i]\n",
    "            end = offers_end[i]\n",
    "            kind = offers_type[i]\n",
    "            reward = offers_reward[i]\n",
    "            difficulty = offers_difficulty[i]\n",
    "            \n",
    "            # identify completion event within the offer\n",
    "            completed_time = None\n",
    "            completed = 0 #0 if no completion even, 1 if completion even\n",
    "            for time, completion_offer_id in offers_completed:\n",
    "                if completion_offer_id == offer_id and time >= start and time <= end:\n",
    "                    completed_time = time\n",
    "                    completed = 1\n",
    "                    break\n",
    "                    \n",
    "            # identify view event within the offer, views after completion will be regarded as not viewed\n",
    "            viewed_time = None\n",
    "            viewed = 0 #0 if no completion even, 1 if completion even\n",
    "            for time, viewed_offer_id in offers_viewed:\n",
    "                if completed_time:\n",
    "                    if time > completed_time: #do not accept if time of viewing is after time of completion\n",
    "                        break\n",
    "                if viewed_offer_id == offer_id and time >= start and time <= end:\n",
    "                        viewed_time = time\n",
    "                        viewed = 1\n",
    "                        break        \n",
    "            \n",
    "            # calculate valid window related parameters\n",
    "            time_in_window = 0\n",
    "            amount_in_window = 0\n",
    "            if viewed:\n",
    "                # time from viewed to completion or end of offer window. \n",
    "                if completed_time:\n",
    "                    time_in_window = completed_time - viewed_time +1\n",
    "                else:\n",
    "                    time_in_window = end - viewed_time +1 \n",
    "                # cumulative amount spent in valid window, if no valid window, no amount spent due to offer\n",
    "                transactions_in_window = user_transactions.loc[(user_transactions['time'] >= viewed_time) &\n",
    "                                                               (user_transactions['time'] <= viewed_time + time_in_window), :]\n",
    "                \n",
    "                amount_in_window = transactions_in_window['amount'].sum()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            offers.update({count: {'offer_id': offer_id,\n",
    "                                   'user_id': user,\n",
    "                                   'offer_type': kind,\n",
    "                                   'difficulty': difficulty,\n",
    "                                   'reward': reward,\n",
    "                                   'start_time': start,\n",
    "                                   'duration': duration,\n",
    "                                   'end_time': end,\n",
    "                                   'viewed': viewed,\n",
    "                                   'view_time': viewed_time,\n",
    "                                   'completed': completed,\n",
    "                                   'complet_time': completed_time,\n",
    "                                   'time_in_window': time_in_window,\n",
    "                                   'amount_in_window': amount_in_window}})\n",
    "            count+=1\n",
    "    dtype = [str, str, str, float, float, float, float, float, int, float, int, float, float, float]\n",
    "    offer_df = pd.DataFrame.from_dict(offers, orient='index')\n",
    "    print(\"{} received no offer\".format(count_users_no_offer))\n",
    "    return offer_df\n",
    "\n",
    "offer_df = build_offer_df(portfolio, profile, transcript)\n",
    "pd.to_pickle(offer_df, 'offer_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>reward</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>end_time</th>\n",
       "      <th>viewed</th>\n",
       "      <th>view_time</th>\n",
       "      <th>completed</th>\n",
       "      <th>complet_time</th>\n",
       "      <th>time_in_window</th>\n",
       "      <th>amount_in_window</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2906b810c7d4411798c6938adc9daaa5</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>240</td>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>348.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>229</td>\n",
       "      <td>10.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>408</td>\n",
       "      <td>240</td>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "      <td>408.0</td>\n",
       "      <td>1</td>\n",
       "      <td>552.0</td>\n",
       "      <td>145</td>\n",
       "      <td>10.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2298d6c36e964ae4a3e7e9706d1fb8c2</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>168</td>\n",
       "      <td>672</td>\n",
       "      <td>1</td>\n",
       "      <td>504.0</td>\n",
       "      <td>1</td>\n",
       "      <td>552.0</td>\n",
       "      <td>49</td>\n",
       "      <td>7.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>240</td>\n",
       "      <td>816</td>\n",
       "      <td>1</td>\n",
       "      <td>582.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235</td>\n",
       "      <td>9.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           offer_id                           user_id  \\\n",
       "0  2906b810c7d4411798c6938adc9daaa5  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "1  0b1e1539f2cc45b7b9fa7c272da2e1d7  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "2  fafdcd668e3743c1bb461111dcafc2a4  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "3  2298d6c36e964ae4a3e7e9706d1fb8c2  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "4  fafdcd668e3743c1bb461111dcafc2a4  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "\n",
       "  offer_type difficulty reward  start_time  duration  end_time  viewed  \\\n",
       "0   discount         10      2         168       168       336       1   \n",
       "1   discount         20      5         336       240       576       1   \n",
       "2   discount         10      2         408       240       648       1   \n",
       "3   discount          7      3         504       168       672       1   \n",
       "4   discount         10      2         576       240       816       1   \n",
       "\n",
       "   view_time  completed  complet_time  time_in_window  amount_in_window  \n",
       "0      216.0          0           NaN             121              0.00  \n",
       "1      348.0          0           NaN             229             10.52  \n",
       "2      408.0          1         552.0             145             10.17  \n",
       "3      504.0          1         552.0              49              7.54  \n",
       "4      582.0          0           NaN             235              9.88  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe for future use. Don't want to remake it every time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allright! We have a matrix with slightly more information. To make all interesting columns ready for a bit of analysis we will introduce dummy variables for the offer_type. Due to the use for the categorical value in data wrangling, I will not delete it. Rather, we will later define a subset of this matrix to be used to different inference methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>offer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>reward</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>end_time</th>\n",
       "      <th>viewed</th>\n",
       "      <th>view_time</th>\n",
       "      <th>completed</th>\n",
       "      <th>complet_time</th>\n",
       "      <th>time_in_window</th>\n",
       "      <th>amount_in_window</th>\n",
       "      <th>type_bogo</th>\n",
       "      <th>type_discount</th>\n",
       "      <th>type_informational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2906b810c7d4411798c6938adc9daaa5</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>168</td>\n",
       "      <td>336</td>\n",
       "      <td>1</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>240</td>\n",
       "      <td>576</td>\n",
       "      <td>1</td>\n",
       "      <td>348.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>229</td>\n",
       "      <td>10.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>408</td>\n",
       "      <td>240</td>\n",
       "      <td>648</td>\n",
       "      <td>1</td>\n",
       "      <td>408.0</td>\n",
       "      <td>1</td>\n",
       "      <td>552.0</td>\n",
       "      <td>145</td>\n",
       "      <td>10.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2298d6c36e964ae4a3e7e9706d1fb8c2</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>504</td>\n",
       "      <td>168</td>\n",
       "      <td>672</td>\n",
       "      <td>1</td>\n",
       "      <td>504.0</td>\n",
       "      <td>1</td>\n",
       "      <td>552.0</td>\n",
       "      <td>49</td>\n",
       "      <td>7.54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>discount</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>576</td>\n",
       "      <td>240</td>\n",
       "      <td>816</td>\n",
       "      <td>1</td>\n",
       "      <td>582.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235</td>\n",
       "      <td>9.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           offer_id                           user_id  \\\n",
       "0  2906b810c7d4411798c6938adc9daaa5  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "1  0b1e1539f2cc45b7b9fa7c272da2e1d7  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "2  fafdcd668e3743c1bb461111dcafc2a4  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "3  2298d6c36e964ae4a3e7e9706d1fb8c2  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "4  fafdcd668e3743c1bb461111dcafc2a4  68be06ca386d4c31939f3a4f0e3dd783   \n",
       "\n",
       "  offer_type difficulty reward  start_time  duration  end_time  viewed  \\\n",
       "0   discount         10      2         168       168       336       1   \n",
       "1   discount         20      5         336       240       576       1   \n",
       "2   discount         10      2         408       240       648       1   \n",
       "3   discount          7      3         504       168       672       1   \n",
       "4   discount         10      2         576       240       816       1   \n",
       "\n",
       "   view_time  completed  complet_time  time_in_window  amount_in_window  \\\n",
       "0      216.0          0           NaN             121              0.00   \n",
       "1      348.0          0           NaN             229             10.52   \n",
       "2      408.0          1         552.0             145             10.17   \n",
       "3      504.0          1         552.0              49              7.54   \n",
       "4      582.0          0           NaN             235              9.88   \n",
       "\n",
       "   type_bogo  type_discount  type_informational  \n",
       "0          0              1                   0  \n",
       "1          0              1                   0  \n",
       "2          0              1                   0  \n",
       "3          0              1                   0  \n",
       "4          0              1                   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offer_df = pd.read_pickle('offer_df.pkl')\n",
    "offer_type_dummies = pd.get_dummies(offer_df.loc[:, 'offer_type'], prefix='type')\n",
    "offer_df = offer_df.merge(offer_type_dummies, left_index=True, right_index=True)\n",
    "pd.to_pickle(offer_df, 'offer_df.pkl')\n",
    "offer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User based interactions\n",
    "\n",
    "The user based interaction matrix is based on the profile matrix. It tries to summarise the users behaviour within an offer period and outside. It is built with several potential features that can help us separate groups and offers. \n",
    "\n",
    "We will use the profile as a basis for expanding it wiht all these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>id</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>None</td>\n",
       "      <td>68be06ca386d4c31939f3a4f0e3dd783</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>2017-07-15</td>\n",
       "      <td>F</td>\n",
       "      <td>0610b486422d4921ae7d2bf64640c50b</td>\n",
       "      <td>112000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>None</td>\n",
       "      <td>38fe809add3b4fcf9315a9694bb96ff5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>F</td>\n",
       "      <td>78afa995795e4d85b5d9ceeca43f5fef</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>None</td>\n",
       "      <td>a03223e636434f42ac4c3df47e8bac43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age became_member_on gender                                id    income\n",
       "0  118       2017-02-12   None  68be06ca386d4c31939f3a4f0e3dd783       NaN\n",
       "1   55       2017-07-15      F  0610b486422d4921ae7d2bf64640c50b  112000.0\n",
       "2  118       2018-07-12   None  38fe809add3b4fcf9315a9694bb96ff5       NaN\n",
       "3   75       2017-05-09      F  78afa995795e4d85b5d9ceeca43f5fef  100000.0\n",
       "4  118       2017-08-04   None  a03223e636434f42ac4c3df47e8bac43       NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_intervals(windows):\n",
    "    \"\"\"\n",
    "    Returns a list of list with merged intervals. Assume sort start times. \n",
    "    Expect a list of list of the form [[starttime, endtime], [starttime, endtime],...]\n",
    "    Sorts by start time and returns a list of list ordered\n",
    "    \"\"\"\n",
    "    if len(windows)==0: \n",
    "        return [[0],[0]]\n",
    "    if np.all([np.isnan(s) for s,e in windows]):\n",
    "        return [[0],[0]]\n",
    "    windows.sort(key=lambda x: x[0])\n",
    "    while np.isnan(windows[0][0]):\n",
    "        windows.pop(0)\n",
    "    intervals = [[windows[0][0], windows[0][1]]]\n",
    "    if len(windows)==1:\n",
    "        return intervals\n",
    "    for start, end in windows[1:]:\n",
    "        if np.isnan(start) or np.isnan(end):\n",
    "            continue\n",
    "        if start < intervals[-1][1]: \n",
    "            if end > intervals[-1][1]: # if start of next window is less than current interval, then change interval end\n",
    "                intervals[-1][1] = end\n",
    "        else:\n",
    "            intervals.append([start, end])\n",
    "    return intervals\n",
    "\n",
    "def build_user_df(portfolio, profile, transcript, offers):\n",
    "    users = np.array(profile['id'])\n",
    "    \n",
    "    user_dict = {}\n",
    "    max_time = transcript.loc[:,'time'].max()\n",
    "\n",
    "    for user in users: \n",
    "        user_transcript = transcript.loc[transcript['id'] == user, :]\n",
    "        \n",
    "        user_transactions = user_transcript.loc[user_transcript['event'] == 'transaction', ['time', 'amount']]    \n",
    "        user_offers = offers[offers['user_id']==user]\n",
    "        \n",
    "        \n",
    "        total_spent = user_transactions['amount'].sum()\n",
    "        #It would be tempting to do: total_spent_in_window = user_offers['amount_in_window'].sum()\n",
    "        # that is not possible since we have overlapping offers, that counts the spending twice. \n",
    "        # Instead we have to mask any transaction in the union of time windows\n",
    "        spent_in_window = 0\n",
    "        spent_in_discount_window = 0\n",
    "        spent_in_bogo_window = 0\n",
    "        spent_in_info_window = 0\n",
    "        spent_no_window = 0\n",
    "        for i, row in user_transactions.iterrows():\n",
    "            #the below test is based on the fact that comparing a value with nan returns false, thus if not viewed, automatically it will be nan\n",
    "            #the test checks if the transaction time is inside any of the \"valid windows\" of all offers given to the user. \n",
    "            transaction_in_window = np.any((user_offers['view_time'] <= row['time']) & \n",
    "                                           (user_offers['view_time'] + user_offers['time_in_window'] >= row['time']))\n",
    "            if transaction_in_window: \n",
    "                spent_in_window += row['amount']\n",
    "            else:\n",
    "                spent_no_window += row['amount']\n",
    "        \n",
    "        assert np.isclose(spent_in_window + spent_no_window, total_spent, rtol=1e-5, atol=1e-3), 'summation of spendings not correct'\n",
    "\n",
    "        # Get amount spent in specific windows. Here, double booking is allowed to happen\n",
    "        spent_in_discount_window = user_offers.loc[user_offers['offer_type']=='discount','amount_in_window'].sum()\n",
    "        spent_in_bogo_window = user_offers.loc[user_offers['offer_type']=='bogo','amount_in_window'].sum()\n",
    "        spent_in_info_window = user_offers.loc[user_offers['offer_type']=='informational','amount_in_window'].sum()\n",
    "        \n",
    "        # Get time spent in any window\n",
    "        windows = list(zip(user_offers['view_time'],  user_offers['view_time'] + user_offers['time_in_window']))        \n",
    "        intervals = merged_intervals(windows)\n",
    "        time_in_windows = min(max_time, np.diff(np.array(intervals).transpose(), axis=0).sum()) #some offers extend outside of last transactions\n",
    "        time_no_windows = max_time - time_in_windows\n",
    "        \n",
    "        windows_discount = list(zip(user_offers.loc[user_offers['offer_type']=='discount', 'view_time'],  \n",
    "                                    user_offers.loc[user_offers['offer_type']=='discount', 'view_time'] + \n",
    "                                    user_offers.loc[user_offers['offer_type']=='discount', 'time_in_window']))\n",
    "        intervals_discount = merged_intervals(windows_discount)\n",
    "        windows_bogo = list(zip(user_offers.loc[user_offers['offer_type']=='bogo', 'view_time'],  \n",
    "                                    user_offers.loc[user_offers['offer_type']=='bogo', 'view_time'] + \n",
    "                                    user_offers.loc[user_offers['offer_type']=='bogo', 'time_in_window']))\n",
    "        intervals_bogo = merged_intervals(windows_bogo)\n",
    "        windows_info = list(zip(user_offers.loc[user_offers['offer_type']=='informational', 'view_time'],  \n",
    "                                    user_offers.loc[user_offers['offer_type']=='informational', 'view_time'] + \n",
    "                                    user_offers.loc[user_offers['offer_type']=='informational', 'time_in_window']))\n",
    "        intervals_info = merged_intervals(windows_info)\n",
    "        time_in_discount = np.diff(np.array(intervals_discount).transpose(), axis=0).sum()\n",
    "        if np.isnan(time_in_discount):\n",
    "            time_in_discount = 0\n",
    "        time_in_bogo = np.diff(np.array(intervals_bogo).transpose(), axis=0).sum()\n",
    "        if np.isnan(time_in_bogo):\n",
    "            time_in_bogo = 0\n",
    "        time_in_info = np.diff(np.array(intervals_info).transpose(), axis=0).sum()\n",
    "        if np.isnan(time_in_info):\n",
    "            time_in_info = 0\n",
    "        \n",
    "        if user_offers.shape[0] == 0:\n",
    "#             print(\"user {} has no offers to extract data from\".format(user))\n",
    "            view_ratio = 0\n",
    "            completion_ratio = 0\n",
    "            view_and_complete_ratio = 0\n",
    "        else:\n",
    "            view_ratio = user_offers['viewed'].sum()/user_offers.shape[0]\n",
    "            completion_ratio = user_offers['completed'].sum()/user_offers.shape[0]\n",
    "            view_and_complete_ratio = user_offers.loc[(user_offers['completed']==1) & (user_offers['viewed']==1),'start_time'].count()/user_offers.shape[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        user_dict.update({user: {'spent_total': total_spent, \n",
    "                                 'spent_in_window': spent_in_window,\n",
    "                                 'spent_no_window': spent_no_window,\n",
    "                                 'spent_in_discount': spent_in_discount_window,\n",
    "                                 'spent_in_bogo': spent_in_bogo_window,\n",
    "                                 'spent_in_informational': spent_in_info_window,\n",
    "                                 'time_in_window': float(time_in_windows) + 1, #add one to avoid infinity for users that view, spend and complete in the same hour\n",
    "                                 'time_no_window': time_no_windows +1 , \n",
    "                                 'time_in_discount': time_in_discount +1,\n",
    "                                 'time_in_bogo': time_in_bogo +1,\n",
    "                                 'time_in_informational': time_in_info +1,\n",
    "                                 'view_ratio': view_ratio,\n",
    "                                 'completion_ratio': completion_ratio,\n",
    "                                 'view_and_complete_ratio': view_and_complete_ratio,\n",
    "                                 'num_offers_received': user_offers.shape[0]}})\n",
    "        \n",
    "    \n",
    "    expanded = pd.DataFrame.from_dict(user_dict, orient='index').reset_index().rename(columns={'index':'user_id'})\n",
    "    \n",
    "    profile_expanded = pd.merge(profile.sort_values('id'), expanded.sort_values('user_id'), left_on='id', right_on='user_id').drop(columns='id')\n",
    "    return profile_expanded\n",
    "    \n",
    "profile_expanded = build_user_df(portfolio, profile, transcript, offer_df)\n",
    "\n",
    "pd.to_pickle(profile_expanded, 'profile_exanded_2.pkl')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with the offer matrix there are columns in the profile_exanded that should be dummies when using it for machine learning. However, for manual inference, it is useful to have the categorical values. Thus, I will keep them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>became_member_on</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>user_id</th>\n",
       "      <th>spent_total</th>\n",
       "      <th>spent_in_window</th>\n",
       "      <th>spent_no_window</th>\n",
       "      <th>spent_in_discount</th>\n",
       "      <th>spent_in_bogo</th>\n",
       "      <th>...</th>\n",
       "      <th>time_in_bogo</th>\n",
       "      <th>time_in_informational</th>\n",
       "      <th>view_ratio</th>\n",
       "      <th>completion_ratio</th>\n",
       "      <th>view_and_complete_ratio</th>\n",
       "      <th>num_offers_received</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>gender_O</th>\n",
       "      <th>gender_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [age, became_member_on, gender, income, user_id, spent_total, spent_in_window, spent_no_window, spent_in_discount, spent_in_bogo, spent_in_informational, time_in_window, time_no_window, time_in_discount, time_in_bogo, time_in_informational, view_ratio, completion_ratio, view_and_complete_ratio, num_offers_received, gender_F, gender_M, gender_O, gender_nan]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_expanded = pd.read_pickle('profile_exanded_2.pkl')\n",
    "gender_dummies = pd.get_dummies(profile_expanded.loc[:,'gender'], prefix='gender', dummy_na=True)\n",
    "profile_expanded = profile_expanded.merge(gender_dummies, left_index=True, right_index=True)\n",
    "pd.to_pickle(profile_expanded, 'profile_expanded.pkl')\n",
    "profile_expanded\n",
    "profile_expanded.loc[profile_expanded['time_in_window'] == 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now I am happy with these matrices. I will modify them and use subsets from them as I see fit in the analysis part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
